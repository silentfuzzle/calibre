__license__   = 'GPL v3'
__copyright__ = '2014, Darko Miletic <darko.miletic at gmail.com>'
'''
www.wired.com
'''

from calibre.web.feeds.news import BasicNewsRecipe

class WiredDailyNews(BasicNewsRecipe):
    title                 = 'Wired Magazine, Monthly Edition'
    __author__            = 'Darko Miletic, update by Zach Lapidus'
    description           = ('Wired is a full-color monthly American magazine, published in both print '
                             'and online editions, that reports on how emerging technologies affect culture,'
                             'the economy and politics.')
    publisher             = 'Conde Nast'
    category              = 'news, IT, computers, technology'
    oldest_article        = 2
    max_articles_per_feed = 200
    no_stylesheets        = True
    encoding              = 'utf-8'
    use_embedded_content  = False
    language              = 'en'
    ignore_duplicate_articles = {'url'}
    remove_empty_feeds    = True
    publication_type      = 'newsportal'
    extra_css             = """
                            .entry-header{
                                          text-transform: uppercase;
                                          vertical-align: baseline;
                                          display: inline;
                                         }
                            """

    remove_tags = [
        dict(name=['meta','link']),
        dict(name='div', attrs={'class':'podcast_storyboard'}),
        dict(id=['sharing', 'social', 'article-tags', 'sidebar']),
                  ]
    keep_only_tags=[
        dict(attrs={'data-js':['post', 'postHeader']}),
    ]

    def parse_wired_index_page(self, num, seen):
        soup   = self.index_to_soup('http://www.wired.com/category/magazine/page/%d' % num)
        for a in soup.find('main').findAll('a', href=True):
            url = a['href']
            if url.startswith('http://www.wired.com/') and url.endswith('/'):
                title = self.tag_to_string(a.find('h2'))
                dateloc = a.find('time')
                date = self.tag_to_string(dateloc)
                if title.lower() != 'read more' and title and url not in seen:
                    seen.add(url)
                    self.log('Found article:', title, 'in page:', num)
                    yield {'title':title, 'date':date, 'url':url, 'description':''}

    def parse_index(self):
        articles = []
        seen = set()
        for num in (1, 2):
            articles.extend(self.parse_wired_index_page(num, seen))
        return [('Articles', articles)]
